{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading dataste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143508</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071270</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164468</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107809</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3    0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4    0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.143508 -0.107582 -0.418263   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.071270 -0.161175  0.088496   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.224292 -0.594609  0.159877   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.164468 -0.177225 -0.222918   \n",
       "771  0.020653  0.029260  0.412254  ... -0.107809 -0.125231 -0.057041   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2   -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4    0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "767 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72      0  \n",
       "768  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00      0  \n",
       "769  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98      0  \n",
       "770 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36      0  \n",
       "771  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79      0  \n",
       "\n",
       "[772 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Ikjot singh\\Coding\\pred_anal\\sampling\\Creditcard_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train y_train split\n",
    "X_train=df.drop(\"Class\",axis=1)\n",
    "y_train=df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after undersampling: Counter({0: 9, 1: 9})\n",
      "Class distribution after oversampling: Counter({0: 763, 1: 763})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have your dataset loaded into X_train and y_train\n",
    "\n",
    "# Instantiate the RandomUnderSampler and RandomOverSampler\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Perform random undersampling\n",
    "X_resampled_under, y_resampled_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Perform random oversampling\n",
    "X_resampled_over, y_resampled_over = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling and oversampling\n",
    "print(\"Class distribution after undersampling:\", Counter(y_resampled_under))\n",
    "print(\"Class distribution after oversampling:\", Counter(y_resampled_over))\n",
    "\n",
    "df=X_resampled_over\n",
    "df['Class']=y_resampled_over\n",
    "samples=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since undersampling generated a very small amount of rows , we will use oversampling to produce more accurate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    207\n",
       "0    177\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple random sampling\n",
    "n = (1.96*1.96*0.5*0.5)//(0.05**2)\n",
    "s1=df.sample(n=int(n), random_state=42)\n",
    "samples.append(s1)\n",
    "s1['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    188\n",
       "1    188\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratified sampling\n",
    "z=1.96\n",
    "p=0.5\n",
    "E=0.05\n",
    "S=0.7\n",
    "sample_size=round((z**2*p*(1-p))/((E/S)**2))\n",
    "\n",
    "s2=df.groupby('Class', group_keys=False).apply(lambda x: x.sample(sample_size))\n",
    "samples.append(s2)\n",
    "s2['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    435\n",
       "0    429\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster sampling\n",
    "z=1.96\n",
    "p=0.5\n",
    "E=0.05\n",
    "C=1.5\n",
    "sample_size=round((z**2*p*(1-p))/((E/C)**2))\n",
    "clusters=2\n",
    "df_new=df\n",
    "N = len(df)\n",
    "K = int(N/sample_size)\n",
    "data = None\n",
    "for k in range(K):\n",
    "    sample_k = df_new.sample(sample_size)\n",
    "    sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
    "    df_new = df_new.drop(index = sample_k.index)\n",
    "    data = pd.concat([data,sample_k],axis = 0)\n",
    "\n",
    "random_chosen_clusters = np.random.randint(0,K,size = clusters)\n",
    "s3 = data[data.cluster.isin(random_chosen_clusters)]\n",
    "s3.drop(['cluster'], axis=1, inplace=True)\n",
    "samples.append(s3)\n",
    "s3['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20\n",
       "1    20\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Systematic Sampling\n",
    "import math as m\n",
    "n=len(df)\n",
    "k=int(m.sqrt(n))\n",
    "s4=df.iloc[::k]\n",
    "samples.append(s4)\n",
    "s4['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    347\n",
       "1      3\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convenience sampling\n",
    "s5=df.head(350)\n",
    "samples.append(s5)\n",
    "s5['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.16570627689361572, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.15179228782653809, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.16959726810455322, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.17291927337646484, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.09570705890655518, pvalue=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1816: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "# Check goodness of each sample using Shapiro-Wilk test\n",
    "for i in range(5):\n",
    "  print(shapiro(samples[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading=['Simple-Random','Stratified','Cluster','Systematic','Convenience']\n",
    "ans=pd.DataFrame(columns=heading, index=['SVM','Logistic Regression','Decision Tree','Random Forest','Naive Bayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Simple-Random Stratified    Cluster Systematic Convenience\n",
      "SVM                     61.458333  65.957447   67.12963       60.0   97.727273\n",
      "Logistic Regression        90.625  88.297872  93.981481       80.0   97.727273\n",
      "Decision Tree           94.791667  96.808511  98.611111       80.0   95.454545\n",
      "Random Forest           98.958333   98.93617      100.0       90.0   97.727273\n",
      "Naive Bayes             98.958333   98.93617      100.0       90.0   97.727273\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(5):\n",
    "  j=0\n",
    "  x_s=samples[i].drop('Class',axis=1)\n",
    "  y_s=samples[i]['Class']\n",
    "  xtrain, xtest, y_train, y_test = train_test_split(x_s ,y_s , random_state=104,test_size=0.25, shuffle=True)\n",
    "\n",
    "  # Applying SVM\n",
    "\n",
    "  clf = SVC(kernel='rbf')\n",
    "  clf.fit(xtrain, y_train)\n",
    "  y_pred=clf.predict(xtest)\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  ans.iloc[j,i]=acc*100\n",
    "\n",
    "  # Applying Logistic Regression\n",
    "\n",
    "  classifier = LogisticRegression(random_state = 0,max_iter=2000)\n",
    "  classifier.fit(xtrain, y_train)\n",
    "  y_pred = classifier.predict(xtest)\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  ans.iloc[j+1,i]=acc*100\n",
    "\n",
    "  # Applying Decision Tree\n",
    "  classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "  classifier.fit(xtrain, y_train)\n",
    "  y_pred = classifier.predict(xtest)\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  ans.iloc[j+2,i]=acc*100\n",
    "\n",
    "  # Applying RandomForest Classifier\n",
    "  clf = RandomForestClassifier(n_estimators = 100)\n",
    "  clf.fit(xtrain, y_train)\n",
    "  y_pred = clf.predict(xtest)\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  ans.iloc[j+3,i]=acc*100\n",
    "\n",
    "  # Applying Naive bayes\n",
    "\n",
    "  model = GaussianNB()\n",
    "  model.fit(xtrain,y_train)\n",
    "  predicted= model.predict(xtest)\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  ans.iloc[j+4,i]=acc*100\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1ae59_row0_col4, #T_1ae59_row1_col4, #T_1ae59_row2_col2, #T_1ae59_row3_col2, #T_1ae59_row4_col2 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1ae59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1ae59_level0_col0\" class=\"col_heading level0 col0\" >Simple-Random</th>\n",
       "      <th id=\"T_1ae59_level0_col1\" class=\"col_heading level0 col1\" >Stratified</th>\n",
       "      <th id=\"T_1ae59_level0_col2\" class=\"col_heading level0 col2\" >Cluster</th>\n",
       "      <th id=\"T_1ae59_level0_col3\" class=\"col_heading level0 col3\" >Systematic</th>\n",
       "      <th id=\"T_1ae59_level0_col4\" class=\"col_heading level0 col4\" >Convenience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1ae59_level0_row0\" class=\"row_heading level0 row0\" >SVM</th>\n",
       "      <td id=\"T_1ae59_row0_col0\" class=\"data row0 col0\" >61.458333</td>\n",
       "      <td id=\"T_1ae59_row0_col1\" class=\"data row0 col1\" >65.957447</td>\n",
       "      <td id=\"T_1ae59_row0_col2\" class=\"data row0 col2\" >67.129630</td>\n",
       "      <td id=\"T_1ae59_row0_col3\" class=\"data row0 col3\" >60.000000</td>\n",
       "      <td id=\"T_1ae59_row0_col4\" class=\"data row0 col4\" >97.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ae59_level0_row1\" class=\"row_heading level0 row1\" >Logistic Regression</th>\n",
       "      <td id=\"T_1ae59_row1_col0\" class=\"data row1 col0\" >90.625000</td>\n",
       "      <td id=\"T_1ae59_row1_col1\" class=\"data row1 col1\" >88.297872</td>\n",
       "      <td id=\"T_1ae59_row1_col2\" class=\"data row1 col2\" >93.981481</td>\n",
       "      <td id=\"T_1ae59_row1_col3\" class=\"data row1 col3\" >80.000000</td>\n",
       "      <td id=\"T_1ae59_row1_col4\" class=\"data row1 col4\" >97.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ae59_level0_row2\" class=\"row_heading level0 row2\" >Decision Tree</th>\n",
       "      <td id=\"T_1ae59_row2_col0\" class=\"data row2 col0\" >94.791667</td>\n",
       "      <td id=\"T_1ae59_row2_col1\" class=\"data row2 col1\" >96.808511</td>\n",
       "      <td id=\"T_1ae59_row2_col2\" class=\"data row2 col2\" >98.611111</td>\n",
       "      <td id=\"T_1ae59_row2_col3\" class=\"data row2 col3\" >80.000000</td>\n",
       "      <td id=\"T_1ae59_row2_col4\" class=\"data row2 col4\" >95.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ae59_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_1ae59_row3_col0\" class=\"data row3 col0\" >98.958333</td>\n",
       "      <td id=\"T_1ae59_row3_col1\" class=\"data row3 col1\" >98.936170</td>\n",
       "      <td id=\"T_1ae59_row3_col2\" class=\"data row3 col2\" >100.000000</td>\n",
       "      <td id=\"T_1ae59_row3_col3\" class=\"data row3 col3\" >90.000000</td>\n",
       "      <td id=\"T_1ae59_row3_col4\" class=\"data row3 col4\" >97.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ae59_level0_row4\" class=\"row_heading level0 row4\" >Naive Bayes</th>\n",
       "      <td id=\"T_1ae59_row4_col0\" class=\"data row4 col0\" >98.958333</td>\n",
       "      <td id=\"T_1ae59_row4_col1\" class=\"data row4 col1\" >98.936170</td>\n",
       "      <td id=\"T_1ae59_row4_col2\" class=\"data row4 col2\" >100.000000</td>\n",
       "      <td id=\"T_1ae59_row4_col3\" class=\"data row4 col3\" >90.000000</td>\n",
       "      <td id=\"T_1ae59_row4_col4\" class=\"data row4 col4\" >97.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1974895bb10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: red' if v else '' for v in is_max]\n",
    "ans.style.apply(highlight_max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
